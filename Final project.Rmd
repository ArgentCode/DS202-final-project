---
title: "Final"
author: "Ngoc Nguyen, Craig Orman"
date: "4/29/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Data Selection
This is how we selected our data and ensured it would be small enough to go on github.
```{r eval = FALSE}
HousingOriginal <- read.csv("properties_2017.csv")
smallData = HousingOriginal %>% select(yearbuilt, bathroomcnt, architecturalstyletypeid, regionidcity, fireplacecnt,
                                       basementsqft, finishedsquarefeet15, landtaxvaluedollarcnt, typeconstructiontypeid, garagetotalsqft,
                                       latitude, longitude, taxvaluedollarcnt)
smallData = smallData %>% filter(bathroomcnt > 0, taxvaluedollarcnt > 999)
samllSampledData = sample_n(smallData, 1000000)
write.csv(samllSampledData,"C:\\Users\\black\\Desktop\\School\\DS 202\\DS202-final-project\\properties_small_2017.csv", row.names = FALSE)
```

## Instantiation
```{r}
library(tidyverse)
HousingOriginal <- read.csv("properties_small_2017.csv")
```
>__Plan__

Requirement: Group work: at least 10 variables, 100 observations and 6 out of the 8 Candidate plots.

  I. Choose the data

  2. Brain storming 
  - questions/ expectation might have on the data ( list all expectations)

  3. Submission for the plan( homework 11)
  
  - the names of all team members that worked on the final project;
  - an overview of the data set you are working with for the final project;
  - a discussion of cleaning steps that are necessary to get the data into the right shape.
  
## Proposal (Homework 11)

Data was acquired from a 2017 kaggle competition, [Zillow Prize: Zillowâ€™s Home Value Prediction (Zestimate)](https://www.kaggle.com/competitions/zillow-prize-1). We specifically used the properties_2017.csv

Project is on [Github](https://github.com/ArgentCode/DS202-final-project).

Our plan is to use the taxvaluedollarcnt as the actual value of the house, and we plan on doing a variety of visualizations and assessments on both the explanatory variables and the response variable. We will be coming at this with a statistics approach as if we were preparing to make a model. We also hope to do a map to visualize the data and see what we can do for that style of visual with coloring and making interesting visuals.

We noticed the data is decently well cleaned. We suspect dealing with the large number of NA's will be a major challenge, but most of the cleaning has occured in the form of reducing. The original data was an almost 700 mb csv file we had to shrink down (Code above on methodology).
II. Clean & Visualize data

  1. Clean
  
  - Are variables in the right format? 
  - factors are factors, date information is in date format?
  - Are levels in the correct order? 
  - Are level names textual information rather than cryptic numbers?
  - Do variable names to be changed for convenience?

  2. Find (visual) summaries of each data variable using diferent plots to see different aspect ( to see weather expectations matchs)
  
  3. Follow up
  
  - compare with our expectations.
  - Find out where the expectations match and where do not. Then find "why" 
    
  4. Visual summary 
  
  - One visual summary chart for each relevant variable
  - Document expectations ( 2 sentences )
  - Emphasize main finding
  

III. Investigate relationship

- Two-way relationship

+ Numeric vs numberic ( using scatterplots) 
+ Numeric vs categorical ( using side by side boxplots or facetted plot)
+ Categorical vs categorical ( using barchart with facetting or other aesthetic)

- Repeat and follow the questions on index 3.
- Include the next variable to find the relationship

IV. Digging deeper with some fancy stuff ( if have time)
- Training some models


